{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, models\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (train_images.shape, train_labels.shape))\n",
    "print('Test: X=%s, y=%s' % (test_images.shape, test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first few images\n",
    "for i in range(1):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(train_images[i], cmap=plt.get_cmap('gray'))\n",
    "    print(train_labels[i])\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angel Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angel_model = models.Sequential()\n",
    "angel_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "angel_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "angel_model.add(layers.AveragePooling2D((2, 2)))\n",
    "angel_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "angel_model.add(layers.Flatten())\n",
    "angel_model.add(layers.Dense(64, activation='relu'))\n",
    "angel_model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angel_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "angel_history = angel_model.fit(train_images, train_labels, batch_size=32, epochs=15,\n",
    "                    callbacks=callback, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Angel's Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(angel_history.history['accuracy'], label='accuracy')\n",
    "plt.plot(angel_history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.96, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = angel_model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "angel_model.save('angel_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### John Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_model = models.Sequential()\n",
    "john_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "john_model.add(layers.AveragePooling2D((2, 2)))\n",
    "john_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "john_model.add(layers.AveragePooling2D((2, 2)))\n",
    "john_model.add(layers.Flatten())\n",
    "john_model.add(layers.Dense(64, activation='relu'))\n",
    "john_model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "john_history = john_model.fit(train_images, train_labels, batch_size=32, epochs=15,\n",
    "                    callbacks=callback, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate John's Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(john_history.history['accuracy'], label='accuracy')\n",
    "plt.plot(john_history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.96, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = john_model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_model.save('john_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justin Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "justin_model = models.Sequential()\n",
    "justin_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "justin_model.add(layers.Dropout(0.2))\n",
    "justin_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "justin_model.add(layers.AveragePooling2D((2, 2)))\n",
    "justin_model.add(layers.Flatten())\n",
    "justin_model.add(layers.Dense(64, activation='relu'))\n",
    "justin_model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "justin_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "justin_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "justin_history = justin_model.fit(train_images, train_labels, batch_size=32, epochs=15,\n",
    "                    callbacks=callback, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(justin_history.history['accuracy'], label='accuracy')\n",
    "plt.plot(justin_history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.96, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = justin_model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "justin_model.save('justin_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models\n",
    "\n",
    "Here we load models into single ensemble model as list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['angel_model', 'john_model', 'justin_model']\n",
    "trained_models = {}\n",
    "\n",
    "for name in model_names:\n",
    "    if os.path.isdir(name):\n",
    "        trained_models[name] = models.load_model(name)\n",
    "    else:\n",
    "        print(f\"Invalid model name {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 5\n",
    "for _ in range(runs):\n",
    "\n",
    "    random_index = random.randint(0, len(test_images) -1)\n",
    "    random_image = test_images[random_index]\n",
    "    image_label = test_labels[random_index]\n",
    "    model_predictions = [None] * len(trained_models.keys())\n",
    "    ensemble_predictions = {}\n",
    "\n",
    "    # Use each individual model to predict\n",
    "    for i, (name, model) in enumerate(trained_models.items()):\n",
    "        model_predictions[i] = np.argmax(model.predict(tf.reshape(random_image, shape=[1, 28, 28, 1])))\n",
    "\n",
    "    # Vote on final output\n",
    "    for pred in model_predictions:\n",
    "        if pred in ensemble_predictions.keys():\n",
    "            ensemble_predictions[pred] += 1\n",
    "        else:\n",
    "            ensemble_predictions[pred] = 1\n",
    "    \n",
    "    print(f'True label:\\t\\t{image_label}')\n",
    "\n",
    "    # All models agree\n",
    "    if len(ensemble_predictions) == 1:\n",
    "        print(f'Ensemble pred. label:\\t{list(ensemble_predictions.keys())[0]}')\n",
    "    \n",
    "    # 1 model disagrees\n",
    "    elif len(ensemble_predictions) == 2:\n",
    "        print(f'Ensemble pred. label:\\t{max(ensemble_predictions, key=ensemble_predictions.get)}')\n",
    "\n",
    "    # all models disagree\n",
    "    # need to return model with best track record\n",
    "    else:\n",
    "        random_pick = random.choice(list(ensemble_predictions.keys()))\n",
    "        print(f'Ensemble pred. label:\\t{random_pick}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating KKanji Datasets (Midterm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kkanji_midterm_dataset_train = tf.keras.utils.image_dataset_from_directory(\n",
    "                                        './midterm_dataset/',\n",
    "                                        validation_split=0.3,\n",
    "                                        subset=\"training\",\n",
    "                                        image_size=(64, 64),\n",
    "                                        batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kkanji_midterm_dataset_val = tf.keras.utils.image_dataset_from_directory(\n",
    "                                        './midterm_dataset/',\n",
    "                                        validation_split=0.3,\n",
    "                                        subset=\"validation\",\n",
    "                                        image_size=(64, 64),\n",
    "                                        batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = new_kkanji_midterm_dataset_train.class_names\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in new_kkanji_midterm_dataset_train.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in new_kkanji_midterm_dataset_train:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data rescaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = new_kkanji_midterm_dataset_train.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Performance Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = new_kkanji_midterm_dataset_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = new_kkanji_midterm_dataset_train.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE the change in input/output dimensions from the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angel_new_model = models.Sequential()\n",
    "angel_new_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "angel_new_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "angel_new_model.add(layers.AveragePooling2D((2, 2)))\n",
    "angel_new_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "angel_new_model.add(layers.Flatten())\n",
    "angel_new_model.add(layers.Dense(64, activation='relu'))\n",
    "angel_new_model.add(layers.Dense(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angel_new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angel_new_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "angel_history = angel_new_model.fit(new_kkanji_midterm_dataset_train, epochs=15,\n",
    "                    callbacks=callback, validation_data=new_kkanji_midterm_dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE let's all try to generate these plots for our presentation next week pls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(angel_history.history['accuracy'], label='accuracy')\n",
    "plt.plot(angel_history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.75, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = angel_new_model.evaluate(new_kkanji_midterm_dataset_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angel_new_model.save('ange_kanji_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('brush_strokes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "425c80cf2732746be3b317b687ca1852eb62c983ce48210a60c1f5072c461cc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
